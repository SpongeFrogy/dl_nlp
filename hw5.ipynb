{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cCQGk2-bayja"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers[torch] peft evaluate accelerate -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    TrainerCallback\n",
        ")\n",
        "import time\n",
        "import psutil\n",
        "import os\n",
        "\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "4h1_qN4reR6x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Load Dataset / base metrics"
      ],
      "metadata": {
        "id": "Q-J4e2HOuUxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"dair-ai/emotion\")\n",
        "print(dataset)\n",
        "\n",
        "print(\"\\nПример строки:\")\n",
        "print(dataset['train'][0])\n",
        "\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "NUM_LABELS = len(dataset['train'].features['label'].names)\n",
        "print(f\"\\nКлассы: {dataset['train'].features['label'].names}\")\n",
        "print(f\"Количество классов: {NUM_LABELS}\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "tokenized_datasets = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"]\n",
        ")\n",
        "\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "\n",
        "tokenized_datasets.set_format(\"torch\")"
      ],
      "metadata": {
        "id": "PW2mBWyNefRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResourceProfilerCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        '''profiling trainings stats'''\n",
        "        super().__init__()\n",
        "        self.start_time = None\n",
        "        self.start_mem = None\n",
        "        self.process = psutil.Process(os.getpid())\n",
        "\n",
        "    def on_train_begin(self, args, state, control, **kwargs):\n",
        "        self.start_time = time.time()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.reset_peak_memory_stats()\n",
        "            self.start_mem = torch.cuda.memory_allocated()\n",
        "        else:\n",
        "            self.start_mem = self.process.memory_info().rss\n",
        "\n",
        "    def on_train_end(self, args, state, control, **kwargs):\n",
        "        self.end_time = time.time()\n",
        "        if torch.cuda.is_available():\n",
        "            self.end_mem = torch.cuda.max_memory_allocated()\n",
        "        else:\n",
        "            self.end_mem = self.process.memory_info().rss\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    metric = evaluate.load(\"accuracy\")\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "ToTYAFQpelYl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    metrics = {}\n",
        "\n",
        "    accuracy_metric = evaluate.load(\"accuracy\")\n",
        "    acc = accuracy_metric.compute(\n",
        "        predictions=np.argmax(eval_pred.predictions, axis=1),\n",
        "        references=eval_pred.label_ids\n",
        "    )[\"accuracy\"]\n",
        "    metrics[\"accuracy\"] = acc\n",
        "\n",
        "    f1_metric = evaluate.load(\"f1\")\n",
        "    f1 = f1_metric.compute(\n",
        "        predictions=np.argmax(eval_pred.predictions, axis=1),\n",
        "        references=eval_pred.label_ids,\n",
        "        average=\"weighted\"\n",
        "    )[\"f1\"]\n",
        "    metrics[\"f1\"] = f1\n",
        "    return metrics\n",
        "\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=NUM_LABELS,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./tmp_eval\",\n",
        "    per_device_eval_batch_size=64,\n",
        "    do_train=False,\n",
        "    do_eval=True,\n",
        "    seed=SEED,\n",
        "    dataloader_drop_last=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Начало базовой оценки модели без дообучения...\")\n",
        "baseline_metrics = trainer.evaluate(tokenized_datasets[\"test\"])\n",
        "\n",
        "print(\"\\nРезультаты базовой оценки:\")\n",
        "print(f\"Test samples: {len(tokenized_datasets['test'])}\")\n",
        "print(f\"Accuracy: {baseline_metrics['eval_accuracy']:.4f}\")\n",
        "print(f\"Weighted F1: {baseline_metrics['eval_f1']:.4f}\\n\")\n",
        "\n",
        "BASELINE_RESULTS = {\n",
        "    \"accuracy\": baseline_metrics[\"eval_accuracy\"],\n",
        "    \"f1\": baseline_metrics[\"eval_f1\"],\n",
        "    \"memory_usage\": None,\n",
        "    \"params\": sum(p.numel() for p in model.parameters())\n",
        "}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    memory_stats = torch.cuda.memory_stats()\n",
        "    BASELINE_RESULTS[\"memory_usage\"] = memory_stats[\"allocated_bytes.all.peak\"] / 1024**3\n",
        "    print(f\"Пиковое использование GPU памяти: {BASELINE_RESULTS['memory_usage']:.2f} GB\")\n",
        "else:\n",
        "    process = psutil.Process(os.getpid())\n",
        "    BASELINE_RESULTS[\"memory_usage\"] = process.memory_info().rss / 1024**3\n",
        "    print(f\"Пиковое использование RAM: {BASELINE_RESULTS['memory_usage']:.2f} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "dpt4aaz4eu-f",
        "outputId": "0373ec3a-b666-4312-d168-8cdbde620694"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-626c607850a6>:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начало базовой оценки модели без дообучения...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:13]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Результаты базовой оценки:\n",
            "Test samples: 2000\n",
            "Accuracy: 0.1360\n",
            "Weighted F1: 0.0458\n",
            "\n",
            "Пиковое использование GPU памяти: 1.49 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Full Finetuning"
      ],
      "metadata": {
        "id": "73pTuHkEurOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=NUM_LABELS,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./full_finetuning\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=50,\n",
        "    save_strategy=\"no\",\n",
        "    seed=SEED,\n",
        "    report_to=\"none\",\n",
        "    load_best_model_at_end=False,\n",
        "    fp16=torch.cuda.is_available(),\n",
        ")\n",
        "\n",
        "profiler = ResourceProfilerCallback()\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[profiler]\n",
        ")\n",
        "\n",
        "print(\"Начало полного дообучения модели...\")\n",
        "start_time = time.time()\n",
        "trainer.train()\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "print(\"\\nОценка на тестовых данных...\")\n",
        "test_metrics = trainer.evaluate(tokenized_datasets[\"test\"])\n",
        "\n",
        "FULL_FINETUNE_RESULTS = {\n",
        "    \"accuracy\": test_metrics[\"eval_accuracy\"],\n",
        "    \"f1\": test_metrics[\"eval_f1\"],\n",
        "    \"training_time\": training_time,\n",
        "    \"params\": sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
        "    \"memory_usage\": (profiler.end_mem - profiler.start_mem)/1024**3 if torch.cuda.is_available()\n",
        "                    else (profiler.end_mem - profiler.start_mem)/1024**3\n",
        "}\n",
        "\n",
        "print(\"\\nРезультаты полного дообучения:\")\n",
        "print(f\"Время обучения: {FULL_FINETUNE_RESULTS['training_time']/60:.1f} минут\")\n",
        "print(f\"Потребление памяти: {FULL_FINETUNE_RESULTS['memory_usage']:.2f} GB\")\n",
        "print(f\"Обучаемые параметры: {FULL_FINETUNE_RESULTS['params']:,}\")\n",
        "print(f\"Test Accuracy: {FULL_FINETUNE_RESULTS['accuracy']:.4f}\")\n",
        "print(f\"Test F1: {FULL_FINETUNE_RESULTS['f1']:.4f}\")\n",
        "\n",
        "trainer.save_model(\"./full_finetuning/final_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "pdR8rVyzgIAE",
        "outputId": "295bc9c6-9f18-43dc-a77b-131332fe702b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начало полного дообучения модели...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1500/1500 05:09, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.217316</td>\n",
              "      <td>0.917500</td>\n",
              "      <td>0.918468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.132400</td>\n",
              "      <td>0.153112</td>\n",
              "      <td>0.933500</td>\n",
              "      <td>0.933430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.091500</td>\n",
              "      <td>0.155981</td>\n",
              "      <td>0.938500</td>\n",
              "      <td>0.938250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Оценка на тестовых данных...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Результаты полного дообучения:\n",
            "Время обучения: 5.2 минут\n",
            "Потребление памяти: 2.59 GB\n",
            "Обучаемые параметры: 109,486,854\n",
            "Test Accuracy: 0.9300\n",
            "Test F1: 0.9293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Linear Probing"
      ],
      "metadata": {
        "id": "4247MMJFu1h6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=NUM_LABELS,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "class CustomClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, hidden_size, num_labels, dropout_prob=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = torch.nn.Dropout(dropout_prob)\n",
        "        self.linear = torch.nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.linear.weight)\n",
        "        self.linear.bias.data.zero_()\n",
        "\n",
        "    def forward(self, features):\n",
        "        x = self.dropout(features)\n",
        "        return self.linear(x)\n",
        "\n",
        "hidden_size = model.config.hidden_size\n",
        "model.classifier = CustomClassificationHead(hidden_size, NUM_LABELS)\n",
        "\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Обучаемых параметров: {trainable_params}\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./linear_probing\",\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=128,\n",
        "    learning_rate=1e-3,\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_steps=30,\n",
        "    seed=SEED,\n",
        "    report_to=\"none\",\n",
        "    fp16=torch.cuda.is_available()\n",
        ")\n",
        "\n",
        "profiler = ResourceProfilerCallback()\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[profiler]\n",
        ")\n",
        "\n",
        "print(\"Начало обучения с Linear Probing...\")\n",
        "start_time = time.time()\n",
        "trainer.train()\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "test_metrics = trainer.evaluate(tokenized_datasets[\"test\"])\n",
        "\n",
        "LINEAR_RESULTS = {\n",
        "    \"accuracy\": test_metrics[\"eval_accuracy\"],\n",
        "    \"f1\": test_metrics[\"eval_f1\"],\n",
        "    \"training_time\": training_time,\n",
        "    \"params\": trainable_params,\n",
        "    \"memory_usage\": (profiler.end_mem - profiler.start_mem)/1024**3\n",
        "}\n",
        "\n",
        "print(\"\\nРезультаты Linear Probing:\")\n",
        "print(f\"Время обучения: {LINEAR_RESULTS['training_time']/60:.1f} мин\")\n",
        "print(f\"Память: {LINEAR_RESULTS['memory_usage']:.2f} GB\")\n",
        "print(f\"Accuracy: {LINEAR_RESULTS['accuracy']:.4f}\")\n",
        "print(f\"F1: {LINEAR_RESULTS['f1']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "NXMIGg-xjJrk",
        "outputId": "5575e1ee-4687-47a1-fd31-2d46779667d1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучаемых параметров: 4614\n",
            "Начало обучения с Linear Probing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [625/625 02:44, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.577700</td>\n",
              "      <td>1.506686</td>\n",
              "      <td>0.442500</td>\n",
              "      <td>0.331843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.539300</td>\n",
              "      <td>1.475309</td>\n",
              "      <td>0.443000</td>\n",
              "      <td>0.336091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.529800</td>\n",
              "      <td>1.461126</td>\n",
              "      <td>0.484000</td>\n",
              "      <td>0.372644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.495000</td>\n",
              "      <td>1.446199</td>\n",
              "      <td>0.476000</td>\n",
              "      <td>0.365838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.467000</td>\n",
              "      <td>1.438907</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.368799</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Результаты Linear Probing:\n",
            "Время обучения: 2.8 мин\n",
            "Память: 0.39 GB\n",
            "Accuracy: 0.4695\n",
            "F1: 0.3638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. PEFT"
      ],
      "metadata": {
        "id": "IBKBsLovu78b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PromptTuningConfig, get_peft_model\n",
        "\n",
        "prompt_config = PromptTuningConfig(\n",
        "    task_type=\"SEQ_CLS\",\n",
        "    num_virtual_tokens=10,\n",
        "    token_dim=model.config.hidden_size,\n",
        "    num_transformer_submodules=1\n",
        ")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=NUM_LABELS,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "model = get_peft_model(model, prompt_config)\n",
        "\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Обучаемых параметров: {trainable_params}\\n\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./prompt_tuning\",\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=32,\n",
        "    learning_rate=1e-4,\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_steps=30,\n",
        "    seed=SEED,\n",
        "    report_to=\"none\",\n",
        "    fp16=torch.cuda.is_available()\n",
        ")\n",
        "\n",
        "profiler = ResourceProfilerCallback()\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[profiler]\n",
        ")\n",
        "\n",
        "print(\"Начало Prompt Tuning...\")\n",
        "start_time = time.time()\n",
        "trainer.train()\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "test_metrics = trainer.evaluate(tokenized_datasets[\"test\"])\n",
        "\n",
        "PROMPT_RESULTS = {\n",
        "    \"accuracy\": test_metrics[\"eval_accuracy\"],\n",
        "    \"f1\": test_metrics[\"eval_f1\"],\n",
        "    \"training_time\": training_time,\n",
        "    \"params\": trainable_params,\n",
        "    \"memory_usage\": (profiler.end_mem - profiler.start_mem)/1024**3\n",
        "}\n",
        "\n",
        "print(\"\\nРезультаты Prompt Tuning:\")\n",
        "print(f\"Время обучения: {PROMPT_RESULTS['training_time']/60:.1f} мин\")\n",
        "print(f\"Память: {PROMPT_RESULTS['memory_usage']:.2f} GB\")\n",
        "print(f\"Accuracy: {PROMPT_RESULTS['accuracy']:.4f}\")\n",
        "print(f\"F1: {PROMPT_RESULTS['f1']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "GWstdSo9kVZ4",
        "outputId": "e162599f-31ff-4c81-fbde-5e764da42c9c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучаемых параметров: 7680\n",
            "\n",
            "Начало Prompt Tuning...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5000/5000 12:14, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.858200</td>\n",
              "      <td>1.849769</td>\n",
              "      <td>0.102000</td>\n",
              "      <td>0.084850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.847300</td>\n",
              "      <td>1.817693</td>\n",
              "      <td>0.182500</td>\n",
              "      <td>0.151028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.816200</td>\n",
              "      <td>1.791637</td>\n",
              "      <td>0.273500</td>\n",
              "      <td>0.180385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.807000</td>\n",
              "      <td>1.772064</td>\n",
              "      <td>0.324000</td>\n",
              "      <td>0.191063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.785700</td>\n",
              "      <td>1.759832</td>\n",
              "      <td>0.338000</td>\n",
              "      <td>0.190736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.791400</td>\n",
              "      <td>1.751523</td>\n",
              "      <td>0.346000</td>\n",
              "      <td>0.189761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.770300</td>\n",
              "      <td>1.746459</td>\n",
              "      <td>0.348500</td>\n",
              "      <td>0.188291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.767800</td>\n",
              "      <td>1.743216</td>\n",
              "      <td>0.351000</td>\n",
              "      <td>0.189033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.773100</td>\n",
              "      <td>1.741363</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>0.187785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.768600</td>\n",
              "      <td>1.740701</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>0.187785</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Результаты Prompt Tuning:\n",
            "Время обучения: 12.3 мин\n",
            "Память: 1.31 GB\n",
            "Accuracy: 0.3465\n",
            "F1: 0.1822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. LoRA"
      ],
      "metadata": {
        "id": "FRQLFUWWu_b1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"query\", \"value\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_CLS\"\n",
        ")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=NUM_LABELS,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Обучаемых параметров: {trainable_params}\\n\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./lora_tuning\",\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=32,\n",
        "    learning_rate=2e-5,\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_steps=30,\n",
        "    seed=SEED,\n",
        "    report_to=\"none\",\n",
        "    fp16=torch.cuda.is_available()\n",
        ")\n",
        "\n",
        "profiler = ResourceProfilerCallback()\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[profiler]\n",
        ")\n",
        "\n",
        "print(\"Начало обучения с LoRA...\")\n",
        "start_time = time.time()\n",
        "trainer.train()\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "test_metrics = trainer.evaluate(tokenized_datasets[\"test\"])\n",
        "\n",
        "LORA_RESULTS = {\n",
        "    \"accuracy\": test_metrics[\"eval_accuracy\"],\n",
        "    \"f1\": test_metrics[\"eval_f1\"],\n",
        "    \"training_time\": training_time,\n",
        "    \"params\": trainable_params,\n",
        "    \"memory_usage\": (profiler.end_mem - profiler.start_mem)/1024**3\n",
        "}\n",
        "\n",
        "print(\"\\nРезультаты LoRA:\")\n",
        "print(f\"Время обучения: {LORA_RESULTS['training_time']/60:.1f} мин\")\n",
        "print(f\"Память: {LORA_RESULTS['memory_usage']:.2f} GB\")\n",
        "print(f\"Accuracy: {LORA_RESULTS['accuracy']:.4f}\")\n",
        "print(f\"F1: {LORA_RESULTS['f1']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "cSqm8KRtnQP8",
        "outputId": "6367afdd-72b9-4a8d-e13a-1398d17634bc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучаемых параметров: 299526\n",
            "\n",
            "Начало обучения с LoRA...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 05:03, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.512600</td>\n",
              "      <td>1.450815</td>\n",
              "      <td>0.481000</td>\n",
              "      <td>0.366448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.290300</td>\n",
              "      <td>1.204424</td>\n",
              "      <td>0.555500</td>\n",
              "      <td>0.433933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.179300</td>\n",
              "      <td>1.153362</td>\n",
              "      <td>0.570000</td>\n",
              "      <td>0.449521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.149700</td>\n",
              "      <td>1.136958</td>\n",
              "      <td>0.574000</td>\n",
              "      <td>0.452511</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Результаты LoRA:\n",
            "Время обучения: 5.1 мин\n",
            "Память: 1.40 GB\n",
            "Accuracy: 0.5840\n",
            "F1: 0.4645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r_values = [4, 8, 16]\n",
        "results = []\n",
        "\n",
        "for r in r_values:\n",
        "    lora_config = LoraConfig(\n",
        "        r=r,\n",
        "        lora_alpha=2*r,\n",
        "        target_modules=[\"query\", \"value\"],\n",
        "        task_type=\"SEQ_CLS\"\n",
        "    )\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        num_labels=NUM_LABELS,\n",
        "        ignore_mismatched_sizes=True\n",
        "    )\n",
        "    model = get_peft_model(model, lora_config)\n",
        "\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Обучаемых параметров: {trainable_params}\\n\")\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./lora_tuning\",\n",
        "        num_train_epochs=4,\n",
        "        per_device_train_batch_size=32,\n",
        "        learning_rate=2e-5,\n",
        "        eval_strategy=\"epoch\",\n",
        "        logging_steps=30,\n",
        "        seed=SEED,\n",
        "        report_to=\"none\",\n",
        "        fp16=torch.cuda.is_available()\n",
        "    )\n",
        "\n",
        "    profiler = ResourceProfilerCallback()\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_datasets[\"train\"],\n",
        "        eval_dataset=tokenized_datasets[\"validation\"],\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[profiler]\n",
        "    )\n",
        "\n",
        "    print(\"Начало обучения с LoRA...\")\n",
        "    start_time = time.time()\n",
        "    trainer.train()\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    test_metrics = trainer.evaluate(tokenized_datasets[\"test\"])\n",
        "\n",
        "    RESULTS = {\n",
        "        \"accuracy\": test_metrics[\"eval_accuracy\"],\n",
        "        \"f1\": test_metrics[\"eval_f1\"],\n",
        "        \"training_time\": training_time,\n",
        "        \"params\": trainable_params,\n",
        "        \"memory_usage\": (profiler.end_mem - profiler.start_mem)/1024**3\n",
        "    }\n",
        "\n",
        "    results.append({\n",
        "        \"r\": r,\n",
        "        \"RESULTS\": RESULTS\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "lEntlXeethQm",
        "outputId": "0845c5ea-fc56-4705-8e2d-2bb950d89c3b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучаемых параметров: 152070\n",
            "\n",
            "Начало обучения с LoRA...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 05:13, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.569200</td>\n",
              "      <td>1.556132</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.252030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.520700</td>\n",
              "      <td>1.471571</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.340274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.384800</td>\n",
              "      <td>1.350873</td>\n",
              "      <td>0.510500</td>\n",
              "      <td>0.396351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.337500</td>\n",
              "      <td>1.325800</td>\n",
              "      <td>0.515000</td>\n",
              "      <td>0.400620</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучаемых параметров: 299526\n",
            "\n",
            "Начало обучения с LoRA...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 04:51, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.553300</td>\n",
              "      <td>1.532512</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.277798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.386500</td>\n",
              "      <td>1.310184</td>\n",
              "      <td>0.525500</td>\n",
              "      <td>0.409806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.287600</td>\n",
              "      <td>1.249239</td>\n",
              "      <td>0.544000</td>\n",
              "      <td>0.426031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.262300</td>\n",
              "      <td>1.235300</td>\n",
              "      <td>0.545000</td>\n",
              "      <td>0.427395</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучаемых параметров: 594438\n",
            "\n",
            "Начало обучения с LoRA...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 04:52, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.461100</td>\n",
              "      <td>1.390125</td>\n",
              "      <td>0.499000</td>\n",
              "      <td>0.384541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.287300</td>\n",
              "      <td>1.207331</td>\n",
              "      <td>0.559000</td>\n",
              "      <td>0.437578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.187400</td>\n",
              "      <td>1.153918</td>\n",
              "      <td>0.571500</td>\n",
              "      <td>0.449954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.176400</td>\n",
              "      <td>1.139394</td>\n",
              "      <td>0.573500</td>\n",
              "      <td>0.451351</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получаем, что параметры\n",
        "```\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"query\", \"value\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_CLS\"\n",
        ")\n",
        "```\n",
        "дают лучший результат"
      ],
      "metadata": {
        "id": "YOYC35u8x2PG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Results"
      ],
      "metadata": {
        "id": "KqOFb6AavHEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "results_table = [\n",
        "    [\"Method\", \"Accuracy\", \"F1\", \"Time (min)\", \"Params\", \"Memory (GB)\"],\n",
        "    [\"Baseline (no tune)\",\n",
        "     f\"{BASELINE_RESULTS['accuracy']:.3f}\",\n",
        "     f\"{BASELINE_RESULTS['f1']:.3f}\",\n",
        "     \"-\",\n",
        "     \"-\",\n",
        "     f\"{BASELINE_RESULTS['memory_usage']:.1f}\"],\n",
        "\n",
        "    [\"Full Finetuning\",\n",
        "     f\"{FULL_FINETUNE_RESULTS['accuracy']:.3f}\",\n",
        "     f\"{FULL_FINETUNE_RESULTS['f1']:.3f}\",\n",
        "     f\"{FULL_FINETUNE_RESULTS['training_time']/60:.1f}\",\n",
        "     f\"{FULL_FINETUNE_RESULTS['params']/1e6:.1f}M\",\n",
        "     f\"{FULL_FINETUNE_RESULTS['memory_usage']:.1f}\"],\n",
        "\n",
        "    [\"Linear Probing\",\n",
        "     f\"{LINEAR_RESULTS['accuracy']:.3f}\",\n",
        "     f\"{LINEAR_RESULTS['f1']:.3f}\",\n",
        "     f\"{LINEAR_RESULTS['training_time']/60:.1f}\",\n",
        "     f\"{LINEAR_RESULTS['params']/1e3:.1f}K\",\n",
        "     f\"{LINEAR_RESULTS['memory_usage']:.1f}\"],\n",
        "\n",
        "    [\"Prompt Tuning\",\n",
        "     f\"{PROMPT_RESULTS['accuracy']:.3f}\",\n",
        "     f\"{PROMPT_RESULTS['f1']:.3f}\",\n",
        "     f\"{PROMPT_RESULTS['training_time']/60:.1f}\",\n",
        "     f\"{PROMPT_RESULTS['params']/1e3:.1f}K\",\n",
        "     f\"{PROMPT_RESULTS['memory_usage']:.1f}\"],\n",
        "\n",
        "    [\"LoRA (r=8)\",\n",
        "     f\"{LORA_RESULTS['accuracy']:.3f}\",\n",
        "     f\"{LORA_RESULTS['f1']:.3f}\",\n",
        "     f\"{LORA_RESULTS['training_time']/60:.1f}\",\n",
        "     f\"{LORA_RESULTS['params']/1e6:.1f}M\",\n",
        "     f\"{LORA_RESULTS['memory_usage']:.1f}\"]\n",
        "]\n",
        "\n",
        "print(\"\\nСводная таблица результатов:\")\n",
        "print(tabulate(results_table, headers=\"firstrow\", tablefmt=\"github\", stralign=\"center\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp_RTbmso1cY",
        "outputId": "066d9d95-bd1c-4653-ca9e-fbe70d8a6885"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Сводная таблица результатов:\n",
            "|       Method       |   Accuracy |    F1 |  Time (min)  |  Params  |   Memory (GB) |\n",
            "|--------------------|------------|-------|--------------|----------|---------------|\n",
            "| Baseline (no tune) |      0.136 | 0.046 |      -       |    -     |           1.5 |\n",
            "|  Full Finetuning   |      0.93  | 0.929 |     5.2      |  109.5M  |           2.6 |\n",
            "|   Linear Probing   |      0.469 | 0.364 |     2.8      |   4.6K   |           0.4 |\n",
            "|   Prompt Tuning    |      0.346 | 0.182 |     12.3     |   7.7K   |           1.3 |\n",
            "|     LoRA (r=8)     |      0.584 | 0.464 |     5.1      |   0.3M   |           1.4 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод:\n",
        "\n",
        " - Full Finetuning показал максимальное качество, что ожидаемо, так как все параметры модели адаптируются под задачу.\n",
        " - LoRA демонстрирует лучший баланс среди PEFT-методов, но его качество значительно уступает полному дообучению.\n",
        " - Prompt Tuning работает хуже Linear Probing, что противоречит ожиданиям.     \n",
        "    Возможные причины:\n",
        "    - Неоптимальные гиперпараметры (например, мало виртуальных токенов).\n",
        "    - Специфика датасета (короткие тексты, слабая связь с промптами).\n",
        " - Baseline (no tune) подтверждает, что предобученная модель без дообучения не подходит для задачи классификации эмоций."
      ],
      "metadata": {
        "id": "iELf9yAsqMTx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B8afTPF-yOon"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}