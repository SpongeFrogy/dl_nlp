{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import corus\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load `lenta-ru-news` / split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already loaded.\n"
     ]
    }
   ],
   "source": [
    "DATA_SIZE = 100_000 # cut off size for faster performance\n",
    "\n",
    "path = 'lenta-ru-news.csv.gz'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    !wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
    "else:\n",
    "    print(\"Already loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load lenta: 739351it [00:21, 34350.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153198</th>\n",
       "      <td>EgyptAir объявила о подорожании билетов</td>\n",
       "      <td>Египетский перевозчик EgyptAir сообщил о возмо...</td>\n",
       "      <td>Путешествия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169154</th>\n",
       "      <td>Глава Красногорского района Подмосковья ушел в...</td>\n",
       "      <td>Глава Красногорского района Московской области...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83745</th>\n",
       "      <td>Милонов предложил запретить россиянам сидеть в...</td>\n",
       "      <td>Депутат Виталий Милонов внес в Госдуму законоп...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10029</th>\n",
       "      <td>Женщинам в детородном возрасте разрешили посещ...</td>\n",
       "      <td>Верховный суд Индии разрешил женщинам в фертил...</td>\n",
       "      <td>Мир</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6445</th>\n",
       "      <td>Россиянам пообещали дешевый хлеб</td>\n",
       "      <td>Россиянам не стоит бояться роста цен на хлеб —...</td>\n",
       "      <td>Экономика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45187</th>\n",
       "      <td>МОК наказал Мутко</td>\n",
       "      <td>Российский вице-премьер Виталий Мутко пожизнен...</td>\n",
       "      <td>Спорт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399176</th>\n",
       "      <td>Жара резко увеличила энергопотребление в Москве</td>\n",
       "      <td>Потребление электроэнергии в Москве в последни...</td>\n",
       "      <td>Экономика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66430</th>\n",
       "      <td>Федор Емельяненко и Милонов снимутся во «Лжи М...</td>\n",
       "      <td>На Урале снимут картину «Ложь Матильды», посвя...</td>\n",
       "      <td>Культура</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78735</th>\n",
       "      <td>Трамп высмеял противившихся увольнению директо...</td>\n",
       "      <td>Президент США Дональд Трамп опубликовал подбор...</td>\n",
       "      <td>Мир</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102670</th>\n",
       "      <td>В Москве подтвердили передачу Сербии шести ист...</td>\n",
       "      <td>Весной 2017 года Сербия получит шесть истребит...</td>\n",
       "      <td>Силовые структуры</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "153198           EgyptAir объявила о подорожании билетов    \n",
       "169154  Глава Красногорского района Подмосковья ушел в...   \n",
       "83745   Милонов предложил запретить россиянам сидеть в...   \n",
       "10029   Женщинам в детородном возрасте разрешили посещ...   \n",
       "6445                     Россиянам пообещали дешевый хлеб   \n",
       "45187                                   МОК наказал Мутко   \n",
       "399176    Жара резко увеличила энергопотребление в Москве   \n",
       "66430   Федор Емельяненко и Милонов снимутся во «Лжи М...   \n",
       "78735   Трамп высмеял противившихся увольнению директо...   \n",
       "102670  В Москве подтвердили передачу Сербии шести ист...   \n",
       "\n",
       "                                                     text              topic  \n",
       "153198  Египетский перевозчик EgyptAir сообщил о возмо...        Путешествия  \n",
       "169154  Глава Красногорского района Московской области...             Россия  \n",
       "83745   Депутат Виталий Милонов внес в Госдуму законоп...             Россия  \n",
       "10029   Верховный суд Индии разрешил женщинам в фертил...                Мир  \n",
       "6445    Россиянам не стоит бояться роста цен на хлеб —...          Экономика  \n",
       "45187   Российский вице-премьер Виталий Мутко пожизнен...              Спорт  \n",
       "399176  Потребление электроэнергии в Москве в последни...          Экономика  \n",
       "66430   На Урале снимут картину «Ложь Матильды», посвя...           Культура  \n",
       "78735   Президент США Дональд Трамп опубликовал подбор...                Мир  \n",
       "102670  Весной 2017 года Сербия получит шесть истребит...  Силовые структуры  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = corus.load_lenta(path)\n",
    "def parse(record) -> dict[str, str]:\n",
    "    return dict(title=record.title, text=record.text, topic=record.topic)\n",
    "df = pd.DataFrame(list(tqdm(map(lambda r: parse(r), records), desc='load lenta')))\n",
    "df = df.sample(DATA_SIZE, random_state=42)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.1 Clear up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy3\n",
    "\n",
    "\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "russian_stopwords = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "@functools.lru_cache(maxsize=100_000)\n",
    "def normalize(token):\n",
    "    return morph.parse(token)[0].normal_form\n",
    "\n",
    "@functools.lru_cache(maxsize=100_000)\n",
    "def normalize_with_pos(token):\n",
    "    parse = morph.parse(token)[0]\n",
    "    return f'{parse.normal_form}_{parse.tag.POS}'\n",
    "\n",
    "\n",
    "def preprocess_text(text: str, normalize: Callable[[str], str] = normalize) -> str:\n",
    "    text = re.sub(r'[^а-яё\\s]', '', text.lower())\n",
    "    return ' '.join(\n",
    "        filter(\n",
    "            lambda token: token not in russian_stopwords,\n",
    "            map(\n",
    "                normalize,\n",
    "                text.split()\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocess text: 100%|██████████| 100000/100000 [01:32<00:00, 1081.01it/s]\n"
     ]
    }
   ],
   "source": [
    "df['processed_text'] = list(tqdm(map(\n",
    "    preprocess_text, df['text'].to_list()), desc='preprocess text', total=len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocess text: 100%|██████████| 100000/100000 [01:34<00:00, 1055.49it/s]\n"
     ]
    }
   ],
   "source": [
    "df['processed_text_with_pos'] = list(tqdm(map(\n",
    "    lambda text: preprocess_text(text, normalize_with_pos), df['text'].to_list()), desc='preprocess text', total=len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.2 Drop not representative classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal topic frequency: 1000\n"
     ]
    }
   ],
   "source": [
    "MIN_TOPIC_FREQ = int(.01*len(df))\n",
    "assert MIN_TOPIC_FREQ > 3, 'Too small MIN_TOPIC_FREQ for split train/val/test'\n",
    "print(f'Minimal topic frequency: {MIN_TOPIC_FREQ}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics with counts before preprocessing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "topic\n",
       "Россия               21871\n",
       "Мир                  18494\n",
       "Экономика            10737\n",
       "Спорт                 8632\n",
       "Культура              7337\n",
       "Наука и техника       7129\n",
       "Бывший СССР           7100\n",
       "Интернет и СМИ        6181\n",
       "Из жизни              3718\n",
       "Дом                   2891\n",
       "Силовые структуры     2661\n",
       "Ценности              1079\n",
       "Бизнес                 967\n",
       "Путешествия            855\n",
       "69-я параллель         178\n",
       "Крым                    82\n",
       "Культпросвет            45\n",
       "                        23\n",
       "Легпром                 10\n",
       "Библиотека               8\n",
       "Сочи                     1\n",
       "Оружие                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Topics with counts before preprocessing')\n",
    "df['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Strategy(Enum):\n",
    "    \"\"\"\n",
    "    Тут отразил разные стратегии для решения проблемы нерепрезентативности классов\n",
    "    \"\"\"\n",
    "    NONE = 0  # ничего не делаем\n",
    "    DROP = 1  # опускаем нерепрезентативные классы\n",
    "    REPLACE_WITH_OTHER = 2  # скидываем из в кучу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRATEGY = Strategy.REPLACE_WITH_OTHER\n",
    "\n",
    "match STRATEGY:\n",
    "    case Strategy.NONE:\n",
    "        pass\n",
    "    case Strategy.DROP:\n",
    "        _counts = df['topic'].value_counts()\n",
    "        _keep = (_counts[_counts > MIN_TOPIC_FREQ]).index.to_list()\n",
    "        df = df[df['topic'].apply(lambda x: x in _keep)]\n",
    "    case Strategy.REPLACE_WITH_OTHER:\n",
    "        _counts = df['topic'].value_counts()\n",
    "        _keep = (_counts[_counts > MIN_TOPIC_FREQ]).index.to_list()\n",
    "        df['topic'] = df['topic'].apply(\n",
    "            lambda x: 'other' if x not in _keep else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics with counts after preprocessing with strategy `REPLACE_WITH_OTHER`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "topic\n",
       "Россия               21871\n",
       "Мир                  18494\n",
       "Экономика            10737\n",
       "Спорт                 8632\n",
       "Культура              7337\n",
       "Наука и техника       7129\n",
       "Бывший СССР           7100\n",
       "Интернет и СМИ        6181\n",
       "Из жизни              3718\n",
       "Дом                   2891\n",
       "Силовые структуры     2661\n",
       "other                 2170\n",
       "Ценности              1079\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Topics with counts after preprocessing with strategy `{STRATEGY.name}`')\n",
    "df['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.3 Train/Test/Val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 60000, 0.60%\n",
      "Val size: 20000, 0.20%\n",
      "Test size: 20000, 0.20%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['processed_text']\n",
    "\n",
    "y = df['topic']\n",
    "\n",
    "def train_test_val_split(X, y, sizes: tuple[float, float, float] = (0.6, 0.2, 0.2), random_state=42):\n",
    "    train_size, test_size, val_size = sizes\n",
    "    \n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=test_size + val_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=test_size / (1 - train_size), stratify=y_temp, random_state=42\n",
    "    )\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_test_val_split(X, y)\n",
    "\n",
    "assert len(X_train) + len(X_val) + len(X_test) == len(X)\n",
    "assert len(y_train) + len(y_val) + len(y_test) == len(y)\n",
    "assert np.all(sorted(y.unique()) == sorted(y_train.unique()))\n",
    "assert np.all(sorted(y.unique()) == sorted(y_test.unique()))\n",
    "assert np.all(sorted(y.unique()) == sorted(y_val.unique()))\n",
    "\n",
    "print(f'Train size: {len(X_train)}, {len(X_train) / len(X):.2f}%')\n",
    "print(f'Val size: {len(X_val)}, {len(X_val) / len(X):.2f}%')\n",
    "print(f'Test size: {len(X_test)}, {len(X_test) / len(X):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos = df['processed_text_with_pos']\n",
    "\n",
    "X_pos_train, X_pos_val, X_pos_test, y_train, y_val, y_test = train_test_val_split(X_pos, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Word2Vec and Simple validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v = Word2Vec(\n",
    "    sentences=X_train.apply(str.split),\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=10,\n",
    "    workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `vector_size=100`: размерность вектор6ного пространства, берем 100 так как данных не настолько много как в википедии, например\n",
    "- `window=5`: дефолтное значение, небольшие эксперименты показывают что не сильно меняется качество при window=5+-2, а 10 много, сильно чаще может попасть какое-то слово не из контекста (например, слово из другого предложения)\n",
    "- `min_count=10`: империческое число  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Simple Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "class Benchmark:\n",
    "    class TestScore(NamedTuple):\n",
    "        name: str\n",
    "        total: int\n",
    "        correct: int\n",
    "\n",
    "    class __TestAccuracy(NamedTuple):\n",
    "        class Case(NamedTuple):\n",
    "            words: list[str]\n",
    "            correct: str\n",
    "        \n",
    "        name: str\n",
    "        cases: list[Case]\n",
    "\n",
    "    class __TestSimilarity(NamedTuple):\n",
    "        class Case(NamedTuple):\n",
    "            positive: list[str]\n",
    "            negative: list[str]\n",
    "            correct: str\n",
    "        \n",
    "        name: str\n",
    "        cases: list[Case]\n",
    "\n",
    "    __TEST_ACCURACY_: list[__TestAccuracy] = [\n",
    "        __TestAccuracy(\n",
    "            name=\"Политика\",\n",
    "            cases=[\n",
    "                __TestAccuracy.Case([\"путин\", \"зеленский\", \"лукашенко\", \"меркель\", \"телескоп\"], \"телескоп\"),\n",
    "                __TestAccuracy.Case([\"россия\", \"германия\", \"франция\", \"китай\", \"космос\"], \"космос\"),\n",
    "                __TestAccuracy.Case([\"выборы\", \"голосование\", \"кандидат\", \"бюллетень\", \"помидор\"], \"помидор\")\n",
    "            ]\n",
    "        ),\n",
    "        __TestAccuracy(\n",
    "            name=\"Экономика\",\n",
    "            cases=[\n",
    "                __TestAccuracy.Case([\"нефть\", \"газ\", \"уголь\", \"рубль\", \"подушка\"], \"подушка\"),\n",
    "                __TestAccuracy.Case([\"инфляция\", \"дефляция\", \"рецессия\", \"стагнация\", \"попкорн\"], \"попкорн\"),\n",
    "                __TestAccuracy.Case([\"сбербанк\", \"втб\", \"тинькофф\", \"альфабанк\", \"шаурма\"], \"шаурма\")\n",
    "            ]\n",
    "        ),\n",
    "        __TestAccuracy(\n",
    "            name=\"Спорт\",\n",
    "            cases=[\n",
    "                __TestAccuracy.Case([\"футбол\", \"хоккей\", \"теннис\", \"баскетбол\", \"кроссворд\"], \"кроссворд\"),\n",
    "                __TestAccuracy.Case([\"чемпионат\", \"лига\", \"турнир\", \"матч\", \"сковородка\"], \"сковородка\")\n",
    "            ]\n",
    "        ),\n",
    "        __TestAccuracy(\n",
    "            name=\"Технологии\",\n",
    "            cases=[\n",
    "                __TestAccuracy.Case([\"смартфон\", \"ноутбук\", \"планшет\", \"компьютер\", \"дирижабль\"], \"дирижабль\"),\n",
    "                __TestAccuracy.Case([\"программист\", \"разработчик\", \"тестировщик\", \"аналитик\", \"кастрюля\"], \"кастрюля\")\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    __TEST_SIMILARITY_: list[__TestSimilarity] = [\n",
    "        __TestSimilarity(\n",
    "            name=\"Города и страны\",\n",
    "            cases=[\n",
    "                __TestSimilarity.Case([\"россия\", \"москва\"], [\"франция\"], \"париж\"),\n",
    "                __TestSimilarity.Case([\"германия\", \"берлин\"], [\"италия\"], \"рим\")\n",
    "            ]\n",
    "        ),\n",
    "        __TestSimilarity(\n",
    "            name=\"Политика\",\n",
    "            cases=[\n",
    "                __TestSimilarity.Case([\"президент\", \"россия\"], [\"сша\"], \"байден\"),\n",
    "                __TestSimilarity.Case([\"санкция\", \"евросоюз\"], [\"китай\"], \"тайвань\")\n",
    "            ]\n",
    "        ),\n",
    "        __TestSimilarity(\n",
    "            name=\"Экономика\",\n",
    "            cases=[\n",
    "                __TestSimilarity.Case([\"нефть\", \"доллар\"], [\"евро\"], \"рубль\"),\n",
    "                __TestSimilarity.Case([\"криптовалюта\", \"биткоин\"], [\"акция\"], \"блокчейн\")\n",
    "            ]\n",
    "        ),\n",
    "        __TestSimilarity(\n",
    "            name=\"Спорт\",\n",
    "            cases=[\n",
    "                __TestSimilarity.Case([\"месси\", \"футбол\"], [\"хоккей\"], \"овечкин\"),\n",
    "                __TestSimilarity.Case([\"чемпион\", \"победа\"], [\"поражение\"], \"медаль\")\n",
    "            ]\n",
    "        ),\n",
    "        __TestSimilarity(\n",
    "            name=\"Технологии\",\n",
    "            cases=[\n",
    "                __TestSimilarity.Case([\"интеллект\", \"алгоритм\"], [\"человек\"], \"нейросеть\"),\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    @classmethod\n",
    "    def __bench_accuracy(cls, model: KeyedVectors, test: __TestAccuracy) -> TestScore:\n",
    "        cnt = 0\n",
    "        for case in test.cases:\n",
    "            answer = model.doesnt_match(case.words)\n",
    "            if answer == case.correct: cnt += 1\n",
    "        return cls.TestScore(name=test.name, total=len(test.cases), correct=cnt)\n",
    "\n",
    "    @classmethod\n",
    "    def __bench_top_similarity(cls, model: KeyedVectors, topn: int, test: __TestSimilarity) -> TestScore:\n",
    "        cnt = 0\n",
    "        for case in test.cases:\n",
    "            answer = model.most_similar(\n",
    "                positive=case.positive,\n",
    "                negative=case.negative,\n",
    "                topn=topn\n",
    "            )\n",
    "            if any(map(lambda r: r[0] == case.correct, answer)): cnt += 1\n",
    "        return cls.TestScore(name=test.name, total=len(test.cases), correct=cnt)\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def accuracy_report(cls, model: KeyedVectors):\n",
    "        report = ''\n",
    "        tests = [cls.__bench_accuracy(model, test) for test in cls.__TEST_ACCURACY_]\n",
    "        total = sum(map(lambda a: a.total, tests))\n",
    "        correct = sum(map(lambda a: a.correct, tests))\n",
    "        report += f'Total Accuracy: {correct / total:.4f} (total {total})\\n'\n",
    "        report += '---------------------------------------\\n'\n",
    "        for test in tests:\n",
    "            report += f'{test.name}: {test.correct / test.total:.4f} (total {test.total})\\n' \n",
    "        print(report)\n",
    "\n",
    "    @classmethod\n",
    "    def similarity_report(cls, model: KeyedVectors, topn: int = 10):\n",
    "        report = ''\n",
    "        tests = [cls.__bench_top_similarity(model, topn, test) for test in cls.__TEST_SIMILARITY_]\n",
    "        total = sum(map(lambda a: a.total, tests))\n",
    "        correct = sum(map(lambda a: a.correct, tests))\n",
    "        report += f'Total Accuracy@{topn}: {correct / total:.4f} (total {total})\\n'\n",
    "        report += '---------------------------------------\\n'\n",
    "        for test in tests:\n",
    "            report += f'{test.name}: {test.correct / test.total:.4f} (total {test.total})\\n' \n",
    "        print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy: 0.7000 (total 10)\n",
      "---------------------------------------\n",
      "Политика: 1.0000 (total 3)\n",
      "Экономика: 0.6667 (total 3)\n",
      "Спорт: 0.0000 (total 2)\n",
      "Технологии: 1.0000 (total 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Benchmark.accuracy_report(w2v.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy@5: 0.1111 (total 9)\n",
      "---------------------------------------\n",
      "Города и страны: 0.5000 (total 2)\n",
      "Политика: 0.0000 (total 2)\n",
      "Экономика: 0.0000 (total 2)\n",
      "Спорт: 0.0000 (total 2)\n",
      "Технологии: 0.0000 (total 1)\n",
      "\n",
      "Total Accuracy@100: 0.3333 (total 9)\n",
      "---------------------------------------\n",
      "Города и страны: 0.5000 (total 2)\n",
      "Политика: 0.0000 (total 2)\n",
      "Экономика: 0.5000 (total 2)\n",
      "Спорт: 0.5000 (total 2)\n",
      "Технологии: 0.0000 (total 1)\n",
      "\n",
      "Total Accuracy@1000: 0.3333 (total 9)\n",
      "---------------------------------------\n",
      "Города и страны: 0.5000 (total 2)\n",
      "Политика: 0.0000 (total 2)\n",
      "Экономика: 0.5000 (total 2)\n",
      "Спорт: 0.5000 (total 2)\n",
      "Технологии: 0.0000 (total 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tops = [5, 100, 1_000]\n",
    "for top in tops:\n",
    "    Benchmark.similarity_report(w2v.wv, top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "небольшой бенчмарк, показывает, насколько хорошо веторы описывают текст новостей. Видим, что нет смысла использовать большой топ по похожести, достаточно небольшого колличества, чтобы получить почти максимальное качество"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load navec, rusvectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec\n",
    "\n",
    "\n",
    "path = 'navec_news_v1_1B_250K_300d_100q.tar'\n",
    "navec = Navec.load(path)\n",
    "assert np.allclose(navec['человек'][:15], np.array([-0.13068067, -0.12051002, -0.05782367,  0.07967507,  0.08338855,\n",
    "        0.59920526,  0.4020081 , -1.0838276 ,  0.12556174,  0.17060532,\n",
    "        0.16637331, -0.00257014,  0.51296437,  0.17175263, -0.40394753],\n",
    "      dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import gensim\n",
    "\n",
    "\n",
    "rusvectores_path = 'ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz'\n",
    "if not os.path.exists(rusvectores_path):\n",
    "    urllib.request.urlretrieve(\n",
    "        \"https://rusvectores.org/static/models/rusvectores4/ruwikiruscorpora/ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz\",\n",
    "        \"ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz\"\n",
    "    )\n",
    "\n",
    "model_path = 'ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz'\n",
    "model_ru = gensim.models.KeyedVectors.load_word2vec_format(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Mapping, Optional\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class Pooling:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(documents: list[str]):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, tokens: list[str], vectors: np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "class MeanPooling(Pooling):\n",
    "    def __call__(self, tokens: list[str], vectors: np.ndarray) -> np.ndarray:\n",
    "        return np.mean(vectors, axis=0)\n",
    "\n",
    "\n",
    "class VectorizeAndPool(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model: Mapping[str, np.ndarray],\n",
    "            dim: int,\n",
    "            unk: Optional[str] = None,\n",
    "            pooling: Pooling = MeanPooling()):\n",
    "        self.model = model\n",
    "        self.dim = dim\n",
    "        self.unk = unk\n",
    "        self.pooling = pooling\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if isinstance(self.pooling, TransformerMixin):\n",
    "            self.pooling.fit(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __get_vector(self, token: str) -> np.ndarray:\n",
    "        \"\"\"get vector and handle unknown tokens \n",
    "\n",
    "        :param token: \n",
    "        :type token: str\n",
    "        :return: vector if token is in model, else self.unk (or zeros if unk is None)\n",
    "        :rtype: np.ndarray\n",
    "        \"\"\"\n",
    "        vec = np.zeros((self.dim,), dtype=np.float32)\n",
    "        try:\n",
    "            vec = self.model[token]\n",
    "        except KeyError:\n",
    "            if self.unk is not None:\n",
    "                vec = self.model[self.unk]\n",
    "        return vec\n",
    "\n",
    "    def __get_text_vector(self, text: str) -> np.ndarray:\n",
    "        tokens = text.split()\n",
    "        vectors = np.array(list(map(self.__get_vector, tokens)))\n",
    "        if len(vectors.shape) < 2:\n",
    "            return np.zeros((self.dim,))\n",
    "        return self.pooling(tokens, vectors)\n",
    "\n",
    "    def transform(self, texts: list[str]) -> np.ndarray:\n",
    "        return np.array(list(map(self.__get_text_vector, texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Lenta Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "            other       0.25      0.55      0.34       434\n",
      "      Бывший СССР       0.64      0.76      0.70      1420\n",
      "              Дом       0.66      0.85      0.74       578\n",
      "         Из жизни       0.43      0.70      0.53       743\n",
      "   Интернет и СМИ       0.63      0.67      0.65      1236\n",
      "         Культура       0.84      0.83      0.84      1468\n",
      "              Мир       0.81      0.70      0.75      3699\n",
      "  Наука и техника       0.79      0.75      0.77      1426\n",
      "           Россия       0.82      0.52      0.63      4374\n",
      "Силовые структуры       0.26      0.65      0.37       532\n",
      "            Спорт       0.96      0.95      0.95      1726\n",
      "         Ценности       0.60      0.85      0.71       216\n",
      "        Экономика       0.82      0.76      0.79      2148\n",
      "\n",
      "         accuracy                           0.70     20000\n",
      "        macro avg       0.65      0.73      0.67     20000\n",
      "     weighted avg       0.76      0.70      0.72     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "lenta_vectorized = Pipeline([\n",
    "    ('vec', VectorizeAndPool(\n",
    "        model=w2v.wv,\n",
    "        dim=w2v.vector_size,\n",
    "        unk=None,\n",
    "        pooling=MeanPooling()\n",
    "    )),\n",
    "    ('clf', LogisticRegression(solver='saga', tol=1e-3, max_iter=100, class_weight='balanced', random_state=42))\n",
    "])\n",
    "lenta_vectorized.fit(X_train, y_train)\n",
    "y_val_pred = lenta_vectorized.predict(X_val)\n",
    "print(classification_report(y_val, y_val_pred, zero_division=0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Navec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "            other       0.28      0.55      0.37       434\n",
      "      Бывший СССР       0.72      0.83      0.77      1420\n",
      "              Дом       0.66      0.87      0.75       578\n",
      "         Из жизни       0.46      0.68      0.55       743\n",
      "   Интернет и СМИ       0.67      0.69      0.68      1236\n",
      "         Культура       0.85      0.86      0.85      1468\n",
      "              Мир       0.81      0.72      0.76      3699\n",
      "  Наука и техника       0.77      0.77      0.77      1426\n",
      "           Россия       0.84      0.56      0.68      4374\n",
      "Силовые структуры       0.29      0.66      0.40       532\n",
      "            Спорт       0.96      0.96      0.96      1726\n",
      "         Ценности       0.59      0.85      0.70       216\n",
      "        Экономика       0.82      0.76      0.79      2148\n",
      "\n",
      "         accuracy                           0.73     20000\n",
      "        macro avg       0.67      0.75      0.69     20000\n",
      "     weighted avg       0.77      0.73      0.74     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "navec_vectorized = Pipeline([\n",
    "    ('vec', VectorizeAndPool(\n",
    "        model=navec,\n",
    "        dim=navec.pq.dim,\n",
    "        unk='<unk>',\n",
    "        pooling=MeanPooling()\n",
    "    )),\n",
    "    ('clf', LogisticRegression(solver='saga', tol=1e-3, max_iter=100, class_weight='balanced', random_state=42))\n",
    "])\n",
    "navec_vectorized.fit(X_train, y_train)\n",
    "y_val_pred = navec_vectorized.predict(X_val)\n",
    "print(classification_report(y_val, y_val_pred, zero_division=0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. RusVector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "            other       0.25      0.41      0.31       434\n",
      "      Бывший СССР       0.48      0.66      0.55      1420\n",
      "              Дом       0.56      0.80      0.66       578\n",
      "         Из жизни       0.36      0.63      0.45       743\n",
      "   Интернет и СМИ       0.58      0.62      0.60      1236\n",
      "         Культура       0.80      0.83      0.81      1468\n",
      "              Мир       0.79      0.66      0.72      3699\n",
      "  Наука и техника       0.77      0.70      0.73      1426\n",
      "           Россия       0.75      0.40      0.52      4374\n",
      "Силовые структуры       0.20      0.53      0.29       532\n",
      "            Спорт       0.95      0.92      0.94      1726\n",
      "         Ценности       0.52      0.80      0.63       216\n",
      "        Экономика       0.75      0.77      0.76      2148\n",
      "\n",
      "         accuracy                           0.65     20000\n",
      "        macro avg       0.60      0.67      0.61     20000\n",
      "     weighted avg       0.70      0.65      0.66     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rusvec_vectorized = Pipeline([\n",
    "    ('vec', VectorizeAndPool(\n",
    "        model=model_ru,\n",
    "        dim=300,\n",
    "        unk=None,\n",
    "        pooling=MeanPooling()\n",
    "    )),\n",
    "    ('clf', LogisticRegression(solver='saga', tol=1e-3, max_iter=100, class_weight='balanced', random_state=42))\n",
    "])\n",
    "rusvec_vectorized.fit(X_pos_train, y_train)\n",
    "y_val_pred = rusvec_vectorized.predict(X_pos_val)\n",
    "print(classification_report(y_val, y_val_pred, zero_division=0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем лучший результат с `novec`.\n",
    "\n",
    "Гипотеза: `novec` лучше обученных Word2Vec, так как векторы учились на бОльших данных, лучше `rusvectors`, так как для `rusvectors` нужен POS, который может определяться с ошибками, из-за чего смысл текста в глазах модели будет искажен "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. TfIdfWeighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "class TfIfdWeightsPooling(Pooling):\n",
    "    def __init__(self):\n",
    "        self.log_idf: dict[str, float] = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def tf(tokens: list[str]) -> np.ndarray:\n",
    "        cnts = Counter(tokens)\n",
    "        total = sum(cnts.values())\n",
    "        return np.array([cnts[token] / total for token in tokens], dtype=np.float32)\n",
    "\n",
    "    def idf(self, tokens: list[str]) -> np.ndarray:\n",
    "        return np.array([self.log_idf.get(token, 0.) for token in tokens], dtype=np.float32)\n",
    "\n",
    "    def weights(self, tokens: list[str]) -> np.ndarray:\n",
    "        tf_idf = self.tf(tokens) * self.idf(tokens)\n",
    "        return tf_idf / np.linalg.norm(tf_idf) if max(tf_idf) > 0 else tf_idf # нормализация потому что sklearn ее тоже делает\n",
    "\n",
    "    def fit(self, documents: list[str]):\n",
    "        documents_counts = defaultdict(int)\n",
    "        documents_cnt = len(documents)\n",
    "        for doc in documents:\n",
    "            for token in set(doc.split()):\n",
    "                documents_counts[token] += 1\n",
    "        self.log_idf = {token: np.log(documents_cnt / cnt) + 1 for token, cnt in documents_counts.items()}\n",
    "    \n",
    "\n",
    "    def __call__(self, tokens: list[str], vectors: np.ndarray) -> np.ndarray:\n",
    "        if vectors.ndim != 2:\n",
    "            return vectors\n",
    "        return np.sum(vectors.T * self.weights(tokens), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    train = [\n",
    "        \"Data Science is the sexiest job of the 21st century\",\n",
    "        \"machine learning is the key for data science\"\n",
    "    ]\n",
    "\n",
    "    val = [\n",
    "        \"machine learning is the for job\"\n",
    "    ]\n",
    "\n",
    "    vectorize= TfidfVectorizer(smooth_idf=False, lowercase=False)\n",
    "    pool = TfIfdWeightsPooling()\n",
    "    vectorize.fit(train)\n",
    "    pool.fit(train)\n",
    "\n",
    "    left = vectorize.transform(val).data\n",
    "    right = pool.weights(val[0].split())\n",
    "\n",
    "    assert np.allclose(sorted(left), sorted(right))\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "            other       0.00      0.00      0.00       434\n",
      "      Бывший СССР       0.00      0.00      0.00      1420\n",
      "              Дом       0.00      0.00      0.00       578\n",
      "         Из жизни       0.00      0.00      0.00       743\n",
      "   Интернет и СМИ       0.00      0.00      0.00      1236\n",
      "         Культура       0.00      0.00      0.00      1468\n",
      "              Мир       0.00      0.00      0.00      3699\n",
      "  Наука и техника       0.00      0.00      0.00      1426\n",
      "           Россия       0.00      0.00      0.00      4374\n",
      "Силовые структуры       0.00      0.00      0.00       532\n",
      "            Спорт       0.09      1.00      0.16      1726\n",
      "         Ценности       0.00      0.00      0.00       216\n",
      "        Экономика       0.00      0.00      0.00      2148\n",
      "\n",
      "         accuracy                           0.09     20000\n",
      "        macro avg       0.01      0.08      0.01     20000\n",
      "     weighted avg       0.01      0.09      0.01     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "navec_weighted_vectorized = Pipeline([\n",
    "    ('vec', VectorizeAndPool(\n",
    "        model=navec,\n",
    "        dim=navec.pq.dim,\n",
    "        unk='<unk>',\n",
    "        pooling=TfIfdWeightsPooling()\n",
    "    )),\n",
    "    ('clf', LogisticRegression(solver='saga', tol=1e-3, max_iter=100, class_weight='balanced', random_state=42))\n",
    "])\n",
    "navec_weighted_vectorized.fit(X_train, y_train)\n",
    "y_val_pred = navec_weighted_vectorized.predict(X_val)\n",
    "print(classification_report(y_val, y_val_pred, zero_division=0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf-Idf взвешивание делает сильно хуже.\n",
    "\n",
    "Гипотеза: взвешивание анрушает структуру векторного пространства word2vec и по этому мы теряем сильный сигнал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Total Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "            other       0.24      0.52      0.32       434\n",
      "      Бывший СССР       0.66      0.76      0.70      1420\n",
      "              Дом       0.65      0.84      0.73       578\n",
      "         Из жизни       0.43      0.69      0.53       744\n",
      "   Интернет и СМИ       0.61      0.67      0.64      1236\n",
      "         Культура       0.83      0.82      0.82      1467\n",
      "              Мир       0.82      0.70      0.75      3699\n",
      "  Наука и техника       0.76      0.73      0.74      1426\n",
      "           Россия       0.83      0.53      0.65      4374\n",
      "Силовые структуры       0.26      0.65      0.37       532\n",
      "            Спорт       0.96      0.95      0.96      1727\n",
      "         Ценности       0.62      0.87      0.72       216\n",
      "        Экономика       0.81      0.73      0.77      2147\n",
      "\n",
      "         accuracy                           0.70     20000\n",
      "        macro avg       0.65      0.73      0.67     20000\n",
      "     weighted avg       0.76      0.70      0.71     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lenta_vectorized = Pipeline([\n",
    "    ('vec', VectorizeAndPool(\n",
    "        model=w2v.wv,\n",
    "        dim=w2v.vector_size,\n",
    "        unk=None,\n",
    "        pooling=MeanPooling()\n",
    "    )),\n",
    "    ('clf', LogisticRegression(solver='saga', tol=1e-3, max_iter=100, class_weight='balanced', random_state=42))\n",
    "])\n",
    "lenta_vectorized.fit(X_train, y_train)\n",
    "y_test_pred = lenta_vectorized.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "            other       0.28      0.55      0.37       434\n",
      "      Бывший СССР       0.72      0.83      0.77      1420\n",
      "              Дом       0.66      0.87      0.75       578\n",
      "         Из жизни       0.48      0.70      0.57       744\n",
      "   Интернет и СМИ       0.65      0.71      0.68      1236\n",
      "         Культура       0.85      0.84      0.85      1467\n",
      "              Мир       0.83      0.73      0.78      3699\n",
      "  Наука и техника       0.77      0.75      0.76      1426\n",
      "           Россия       0.84      0.58      0.68      4374\n",
      "Силовые структуры       0.29      0.70      0.41       532\n",
      "            Спорт       0.96      0.96      0.96      1727\n",
      "         Ценности       0.57      0.87      0.69       216\n",
      "        Экономика       0.83      0.75      0.79      2147\n",
      "\n",
      "         accuracy                           0.73     20000\n",
      "        macro avg       0.67      0.76      0.70     20000\n",
      "     weighted avg       0.78      0.73      0.74     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "navec_vectorized = Pipeline([\n",
    "    ('vec', VectorizeAndPool(\n",
    "        model=navec,\n",
    "        dim=navec.pq.dim,\n",
    "        unk='<unk>',\n",
    "        pooling=MeanPooling()\n",
    "    )),\n",
    "    ('clf', LogisticRegression(solver='saga', tol=1e-3, max_iter=100, class_weight='balanced', random_state=42))\n",
    "])\n",
    "navec_vectorized.fit(X_train, y_train)\n",
    "y_test_pred = navec_vectorized.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "            other       0.23      0.38      0.28       434\n",
      "      Бывший СССР       0.48      0.65      0.55      1420\n",
      "              Дом       0.54      0.79      0.64       578\n",
      "         Из жизни       0.36      0.66      0.47       744\n",
      "   Интернет и СМИ       0.55      0.62      0.58      1236\n",
      "         Культура       0.82      0.80      0.81      1467\n",
      "              Мир       0.80      0.66      0.72      3699\n",
      "  Наука и техника       0.74      0.68      0.71      1426\n",
      "           Россия       0.77      0.40      0.53      4374\n",
      "Силовые структуры       0.19      0.54      0.29       532\n",
      "            Спорт       0.95      0.92      0.94      1727\n",
      "         Ценности       0.52      0.87      0.65       216\n",
      "        Экономика       0.74      0.75      0.75      2147\n",
      "\n",
      "         accuracy                           0.64     20000\n",
      "        macro avg       0.59      0.67      0.61     20000\n",
      "     weighted avg       0.70      0.64      0.65     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rusvec_vectorized = Pipeline([\n",
    "    ('vec', VectorizeAndPool(\n",
    "        model=model_ru,\n",
    "        dim=300,\n",
    "        unk=None,\n",
    "        pooling=MeanPooling()\n",
    "    )),\n",
    "    ('clf', LogisticRegression(solver='saga', tol=1e-3, max_iter=100, class_weight='balanced', random_state=42))\n",
    "])\n",
    "rusvec_vectorized.fit(X_pos_train, y_train)\n",
    "y_test_pred = rusvec_vectorized.predict(X_pos_test)\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и предпологалось, лучше всего себя показывает `novec`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
